{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Práctica CNN - Clasificación de imágenes\n",
    "\n",
    "En esta práctica vais a implementar un modelo de clasificación de principio a fin. Esto es, cargado y preparación de los datos, implementación del modelo, entrenamiento del mismo y testeo.\n",
    "\n",
    "Para ello, vamos a emplear una base de datos de imágenes de 5 clases de flores diferentes. La objetivo es desarrollar un modelo de clasificación que sea capaz de diferenciar las distintas clases.\n",
    "\n",
    "Para descargar las imágenes emplea el siguiente código:"
   ],
   "metadata": {
    "id": "xI6jyDM3jKPI"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "data_root = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si vemos la estructura de carpetas de esta base de datos vemos que tenemos una única carpeta dentro de la cual se encuentran todas las imágenes organizadas en carpetas en función de su clase. Con este vamos a crear 2 datasets, el correspondiente a entrenamiento y el correspondiente a validación, haciendo uso de un **tamaño de imagen de 224x224** y un **tamaño de lote de 32**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_SEED = 2055\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=RANDOM_SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_root,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=RANDOM_SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Con esto implementa los siguientes pasos:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Generación de los datasets de entrenamiento y validación (haciendo uso del código anterior). Una vez generado el dataset, visualiza algunas imágenes para garantizar el cargado correcto de las mismas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset.class_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample_images = train_dataset.take(1)\n",
    "\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(train_dataset.class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Normalización de las imágenes en un rango entre 0 y 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def scaling_normalization(image, label):\n",
    "    image = tf.cast(image / 255., tf.float32)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(scaling_normalization)\n",
    "validation_dataset = validation_dataset.map(scaling_normalization)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Implementación de una arquitectura basada en redes neuronales convolucionales para la resolución de un problema de clasificación multiclase."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=[IMG_SIZE[0], IMG_SIZE[1], 3])\n",
    "\n",
    "layer_conv1_1 = layers.Conv2D(filters=2, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", activation=\"relu\")(\n",
    "    input_layer)\n",
    "layer_conv1_2 = layers.Conv2D(filters=2, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", activation=\"relu\")(\n",
    "    layer_conv1_1)\n",
    "layer_pool1 = layers.MaxPool2D(pool_size=(2, 2))(layer_conv1_2)\n",
    "\n",
    "layer_conv3_1 = layers.Conv2D(filters=4, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", activation=\"relu\")(\n",
    "    layer_pool1)\n",
    "layer_conv3_2 = layers.Conv2D(filters=4, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", activation=\"relu\")(\n",
    "    layer_conv3_1)\n",
    "layer_flatten = layers.Flatten()(layer_conv3_2)\n",
    "\n",
    "dense_hidden1 = layers.Dense(32, activation='relu')(layer_flatten)\n",
    "\n",
    "dense_output = layers.Dense(5, activation='softmax')(dense_hidden1)\n",
    "\n",
    "model = Model(inputs=[input_layer], outputs=[dense_output])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Compilación del modelo haciendo uso de una función de pérdidas \"sparse_categorical_crossentropy\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Entrenamiento del modelo durante 15 épocas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "90/92 [============================>.] - ETA: 0s - loss: 0.3203 - accuracy: 0.8993\n",
      "Epoch 1: val_accuracy improved from -inf to 0.45640, saving model to .\\flower_classifier.h5\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.3183 - accuracy: 0.9005 - val_loss: 1.9720 - val_accuracy: 0.4564\n",
      "Epoch 2/15\n",
      "89/92 [============================>.] - ETA: 0s - loss: 0.2512 - accuracy: 0.9291\n",
      "Epoch 2: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.2501 - accuracy: 0.9288 - val_loss: 2.1669 - val_accuracy: 0.4387\n",
      "Epoch 3/15\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9499\n",
      "Epoch 3: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.1923 - accuracy: 0.9499 - val_loss: 2.4012 - val_accuracy: 0.4564\n",
      "Epoch 4/15\n",
      "90/92 [============================>.] - ETA: 0s - loss: 0.1491 - accuracy: 0.9681\n",
      "Epoch 4: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.1473 - accuracy: 0.9687 - val_loss: 2.6891 - val_accuracy: 0.4510\n",
      "Epoch 5/15\n",
      "90/92 [============================>.] - ETA: 0s - loss: 0.1223 - accuracy: 0.9712\n",
      "Epoch 5: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 2s 24ms/step - loss: 0.1243 - accuracy: 0.9700 - val_loss: 2.7595 - val_accuracy: 0.4496\n",
      "Epoch 6/15\n",
      "90/92 [============================>.] - ETA: 0s - loss: 0.1023 - accuracy: 0.9802\n",
      "Epoch 6: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 2s 25ms/step - loss: 0.1018 - accuracy: 0.9802 - val_loss: 3.0346 - val_accuracy: 0.4332\n",
      "Epoch 7/15\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 0.9859\n",
      "Epoch 7: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 2s 23ms/step - loss: 0.0782 - accuracy: 0.9860 - val_loss: 3.1367 - val_accuracy: 0.4414\n",
      "Epoch 8/15\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.9877\n",
      "Epoch 8: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 3s 28ms/step - loss: 0.0724 - accuracy: 0.9877 - val_loss: 3.3939 - val_accuracy: 0.4523\n",
      "Epoch 9/15\n",
      "90/92 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9944\n",
      "Epoch 9: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.0493 - accuracy: 0.9946 - val_loss: 3.6086 - val_accuracy: 0.4550\n",
      "Epoch 10/15\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9949\n",
      "Epoch 10: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.0564 - accuracy: 0.9949 - val_loss: 3.6446 - val_accuracy: 0.4346\n",
      "Epoch 11/15\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9946\n",
      "Epoch 11: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.0413 - accuracy: 0.9946 - val_loss: 3.8364 - val_accuracy: 0.4414\n",
      "Epoch 12/15\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9973\n",
      "Epoch 12: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.0266 - accuracy: 0.9973 - val_loss: 3.9332 - val_accuracy: 0.4469\n",
      "Epoch 13/15\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9983\n",
      "Epoch 13: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.0204 - accuracy: 0.9983 - val_loss: 4.1177 - val_accuracy: 0.4346\n",
      "Epoch 14/15\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9983\n",
      "Epoch 14: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 3s 30ms/step - loss: 0.0167 - accuracy: 0.9983 - val_loss: 4.3156 - val_accuracy: 0.4564\n",
      "Epoch 15/15\n",
      "91/92 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9990\n",
      "Epoch 15: val_accuracy did not improve from 0.45640\n",
      "92/92 [==============================] - 3s 29ms/step - loss: 0.0130 - accuracy: 0.9990 - val_loss: 4.4851 - val_accuracy: 0.4441\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./flower_classifier.h5',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "history_model_base = model.fit(train_dataset, epochs=15, callbacks=[model_checkpoint_callback],\n",
    "                               validation_data=validation_dataset, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T18:38:42.672011100Z",
     "start_time": "2024-01-24T18:38:04.972416100Z"
    }
   },
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Visualización de las curvas de aprendizaje de entrenamiento y validación."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRqnIYyRjDqA"
   },
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    plt.plot(history.history['loss'], label=\"Entrenamiento\")\n",
    "    plt.plot(history.history['val_loss'], label=\"Validación\")\n",
    "    plt.ylabel('Pérdidas')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title('Pérdidas durante el entrenamiento')\n",
    "\n",
    "\n",
    "plot_losses(history_model_base)"
   ]
  }
 ]
}
