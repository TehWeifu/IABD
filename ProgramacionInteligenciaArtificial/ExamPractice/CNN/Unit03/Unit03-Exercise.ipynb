{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Práctica CNN - Clasificación de imágenes\n",
        "\n",
        "En esta práctica vais a implementar un modelo de clasficicación de principio a fin. Esto es, cargado y preparación de los datos, implementación del modelo, entrenamiento del mismo y testeo.\n",
        "\n",
        "Para ello, vamos a emplear una base de datos de imágenes de 5 clases de flores diferentes. La objetivo es desarrollar un modelo de clasificación que sea capaz de diferenciar las distintas clases.\n",
        "\n",
        "Para descargar las imágenes emplea el siguiente código:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "\n",
        "data_root = tf.keras.utils.get_file(\n",
        "  'flower_photos',\n",
        "  'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "   untar=True)\n",
        "```\n",
        "\n",
        "Si vemos la estructura de carpetas de esta base de datos vemos que tenemos una única carpeta dentro de la cual se encuentran todas las imágenes organizadas en carpetas en función de su clase. Con este vamos a crear 2 datasets, el correspondiente a entrenamiento y el correspondiente a validación, haciendo uso de un **tamaño de imagen de 224x224** y un **tamaño de lote de 32**.\n",
        "\n",
        "```\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_root,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_root,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "```\n",
        "\n",
        "Con esto implementa los siguientes pasos:\n",
        "\n",
        "1. Generación de los datasets de entrenamiento y validación (haciendo uso del código anterior). Una vez generado el dataset, visualiza algunas imágenes para garantizar el cargado correcto de las mismas.\n",
        "2. Normalización de las imágenes en un rango entre 0 y 1.\n",
        "3. Implementación de una arquitectura basada en redes neuronales convolucionales para la resolución de un problema de clasificación multiclase.\n",
        "4. Compilación del modelo haciendo uso de una función de pérdidas \"sparse_categorical_crossentropy\".\n",
        "5. Entrenamiento del modelo durante 15 épocas.\n",
        "6. Visualización de las curvas de aprendizaje de entrenamiento y validación.\n",
        "\n"
      ],
      "metadata": {
        "id": "xI6jyDM3jKPI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRqnIYyRjDqA"
      },
      "outputs": [],
      "source": []
    }
  ]
}